# crawling/musinsa_crawler.py

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
import time
import os

def crawl_musinsa():
    options = Options()
    options.add_argument("--headless")  # ì°½ ì•ˆ ë„ìš°ê³  ì‹¤í–‰
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    driver = webdriver.Chrome(options=options)

    url = "https://www.musinsa.com/ranking/best?period=week&mainCategory=001"
    driver.get(url)
    time.sleep(2)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    items = soup.select("li.li_box")
    data = []

    for item in items[:10]:  # ìƒìœ„ 10ê°œë§Œ í…ŒìŠ¤íŠ¸
        try:
            product_link = "https:" + item.select_one(".list_info > a")["href"]
            print("ğŸ‘‰ ìƒí’ˆ ë§í¬:", product_link)
            driver.get(product_link)
            time.sleep(1.5)
            detail_soup = BeautifulSoup(driver.page_source, "html.parser")

            name = detail_soup.select_one("span.product_title").text.strip()
            price = detail_soup.select_one("span.product_article_price").text.strip()
            price = int(price.replace(",", "").replace("ì›", "").strip())

            like_tag = detail_soup.select_one("span.prd_like_cnt")
            like = int(like_tag.text.replace(",", "").strip()) if like_tag else 0

            review_tag = detail_soup.select_one("span.review_cnt")
            review = int(review_tag.text.replace(",", "").replace("ê°œ ë¦¬ë·°", "").strip()) if review_tag else 0

            trend_score = like * 0.6 + review * 1.2

            data.append({
                "ìƒí’ˆëª…": name,
                "ê°€ê²©": price,
                "ì¢‹ì•„ìš”": like,
                "ë¦¬ë·°": review,
                "trend_score": round(trend_score, 2),
                "URL": product_link
            })

        except Exception as e:
            print("âŒ ì—ëŸ¬:", e)

    driver.quit()

    os.makedirs("../data", exist_ok=True)
    df = pd.DataFrame(data)
    df.to_csv("../data/musinsa_trend.csv", index=False, encoding="utf-8-sig")
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ! â†’ data/musinsa_trend.csv ì €ì¥ë¨")

if __name__ == "__main__":
    crawl_musinsa()
